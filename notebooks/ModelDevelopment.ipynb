{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75c53e6",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis – LSTM with Class Weights\n",
    "\n",
    "**Goal:** Build, evaluate, and (later) deploy a sentiment analysis model on  \n",
    "`Twitter_Data.csv` using an LSTM-based deep learning model.\n",
    "\n",
    "We follow this workflow:\n",
    "\n",
    "1. Dataset overview and basic EDA  \n",
    "2. Text cleaning (NLP preprocessing)  \n",
    "3. Train–test split  \n",
    "4. Tokenization and sequence padding  \n",
    "5. Building a BiLSTM model in TensorFlow/Keras  \n",
    "6. Training with EarlyStopping and class weights  \n",
    "7. Model evaluation (accuracy, precision, recall, F1, confusion matrix)  \n",
    "8. Saving the model and tokenizer for deployment (Streamlit app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099b1dd",
   "metadata": {},
   "source": [
    "Imports & configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbb7861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 13:28:28.481046: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-26 13:28:28.561698: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-26 13:28:28.593218: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-26 13:28:28.603179: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-26 13:28:28.658233: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-26 13:28:30.117824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: N/A\n",
      "TensorFlow version: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Imports and global configuration\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# File paths (adapt if your files are in another folder)\n",
    "DATA_PATH = \"Twitter_Data.csv\"        # raw dataset\n",
    "MODEL_PATH = \"sentiment_model.h5\"     # trained Keras model (for Streamlit)\n",
    "TOKENIZER_PATH = \"tokenizer.joblib\"   # saved tokenizer (for Streamlit)\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Model & text hyperparameters\n",
    "MAX_NUM_WORDS = 20000         # vocabulary size for Tokenizer\n",
    "MAX_SEQUENCE_LENGTH = 40      # max tokens per tweet (for padding)\n",
    "EMBEDDING_DIM = 100           # dimension of embedding vectors\n",
    "EPOCHS = 15                   # max epochs (EarlyStopping will likely stop earlier)\n",
    "BATCH_SIZE = 32               # batch size\n",
    "\n",
    "# Mapping between sentiment strings and numeric IDs\n",
    "LABEL_TO_ID = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "ID_TO_LABEL = {v: k for k, v in LABEL_TO_ID.items()}\n",
    "NUM_CLASSES = len(LABEL_TO_ID)\n",
    "\n",
    "print(\"Python version:\", tf.sysconfig.get_build_info().get(\"python_version\", \"N/A\"))\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c9c68",
   "metadata": {},
   "source": [
    "## 1. Load the dataset and basic overview\n",
    "\n",
    "In this step we:\n",
    "\n",
    "- Load `Twitter_Data.csv`\n",
    "- Inspect the first few rows\n",
    "- Check the distribution of the `sentiment` labels\n",
    "- Look at basic statistics of tweet length\n",
    "\n",
    "This gives us an understanding of class balance and the nature of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b38d0",
   "metadata": {},
   "source": [
    "Load and inspect raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43670b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (27481, 4)\n",
      "\n",
      "Columns: ['textID', 'text', 'selected_text', 'sentiment']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment value counts:\n",
      "sentiment\n",
      "neutral     11118\n",
      "positive     8582\n",
      "negative     7781\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Text length (characters) summary:\n",
      "count    27481.000000\n",
      "mean        68.327645\n",
      "std         35.605403\n",
      "min          3.000000\n",
      "25%         39.000000\n",
      "50%         64.000000\n",
      "75%         97.000000\n",
      "max        141.000000\n",
      "Name: text_len, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Load raw dataset and basic EDA\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Raw shape:\", df_raw.shape)\n",
    "print(\"\\nColumns:\", df_raw.columns.tolist())\n",
    "\n",
    "# Show first few rows\n",
    "display(df_raw.head())\n",
    "\n",
    "# Sentiment label distribution\n",
    "print(\"\\nSentiment value counts:\")\n",
    "print(df_raw[\"sentiment\"].value_counts(dropna=False))\n",
    "\n",
    "# Simple length distribution of raw text\n",
    "df_raw[\"text_len\"] = df_raw[\"text\"].astype(str).str.len()\n",
    "print(\"\\nText length (characters) summary:\")\n",
    "print(df_raw[\"text_len\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c4bfe",
   "metadata": {},
   "source": [
    "## 2. NLP preprocessing – cleaning text\n",
    "\n",
    "We now:\n",
    "\n",
    "- Define a `clean_text()` function that:\n",
    "  - Removes URLs  \n",
    "  - Removes @mentions  \n",
    "  - Keeps **letters, spaces, `!`, and `?`** (sentiment-rich punctuation)  \n",
    "  - Lowercases text  \n",
    "  - Collapses multiple spaces\n",
    "\n",
    "- Drop rows with missing `text` or `sentiment`\n",
    "- Apply `clean_text()` to create a `clean_text` column\n",
    "- Drop very short cleaned tweets\n",
    "- Map sentiment labels to numeric IDs (0 = negative, 1 = neutral, 2 = positive)\n",
    "\n",
    "We will **reuse `clean_text()` in the deployment app** so training and inference preprocessing match."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a274907c",
   "metadata": {},
   "source": [
    "Clean text & prepare labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdbf9966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, shape: (27470, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>i d have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>sons of why couldn t they put them on the rele...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                                          clean_text sentiment  label_id  \n",
       "0                 i d have responded if i were going   neutral         1  \n",
       "1      sooo sad i will miss you here in san diego!!!  negative         0  \n",
       "2                             my boss is bullying me  negative         0  \n",
       "3                     what interview! leave me alone  negative         0  \n",
       "4  sons of why couldn t they put them on the rele...  negative         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Define cleaning function and apply it\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple tweet cleaning.\n",
    "\n",
    "    Steps:\n",
    "    - Ensure input is a string\n",
    "    - Remove URLs\n",
    "    - Remove @mentions\n",
    "    - Keep letters, spaces, ! and ?\n",
    "    - Lowercase\n",
    "    - Collapse multiple spaces\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)            # remove URLs\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \" \", text)     # remove @mentions\n",
    "\n",
    "    # Keep letters, spaces, and basic sentiment punctuation ! and ?\n",
    "    text = re.sub(r\"[^a-zA-Z\\s!?]\", \" \", text)\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Drop rows with missing text or sentiment\n",
    "df = df_raw.dropna(subset=[\"text\", \"sentiment\"]).copy()\n",
    "\n",
    "# Apply cleaning\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "# Drop very short cleaned tweets (1–2 characters)\n",
    "df = df[df[\"clean_text\"].str.len() > 2]\n",
    "\n",
    "# Map labels to IDs\n",
    "df[\"label_id\"] = df[\"sentiment\"].map(LABEL_TO_ID)\n",
    "\n",
    "# Drop any rows with unmapped labels (should be none)\n",
    "df = df.dropna(subset=[\"label_id\"])\n",
    "df[\"label_id\"] = df[\"label_id\"].astype(int)\n",
    "\n",
    "print(\"After cleaning, shape:\", df.shape)\n",
    "display(df[[\"text\", \"clean_text\", \"sentiment\", \"label_id\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fb158",
   "metadata": {},
   "source": [
    "## 3. Split into train and test sets\n",
    "\n",
    "We now split:\n",
    "\n",
    "- `X` – the features (cleaned tweets)\n",
    "- `y` – the numeric labels (0/1/2)\n",
    "\n",
    "We use a **stratified train–test split** so that the class distribution is similar\n",
    "in the train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d41e1f",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01737f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 21976, Test size: 5494\n",
      "\n",
      "Train label distribution:\n",
      "neutral     8888\n",
      "positive    6866\n",
      "negative    6222\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test label distribution:\n",
      "neutral     2222\n",
      "positive    1716\n",
      "negative    1556\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Train–test split (stratified)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "X = df[\"clean_text\"].values   # numpy array of strings\n",
    "y = df[\"label_id\"].values     # numpy array of ints\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n",
    "print(\"\\nTrain label distribution:\")\n",
    "print(pd.Series(y_train).map(ID_TO_LABEL).value_counts())\n",
    "\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(pd.Series(y_test).map(ID_TO_LABEL).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5756aec8",
   "metadata": {},
   "source": [
    "## 4. Tokenization and sequence padding\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Create a Keras `Tokenizer` with a fixed vocabulary size and `<OOV>` token  \n",
    "2. Fit it **only on training texts** (best practice)  \n",
    "3. Convert train and test texts to integer sequences  \n",
    "4. Pad/truncate sequences to a fixed length (`MAX_SEQUENCE_LENGTH`)\n",
    "\n",
    "Outputs:\n",
    "\n",
    "- `X_train_pad`: (n_train, max_len) integer array  \n",
    "- `X_test_pad`: (n_test, max_len) integer array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b862f10",
   "metadata": {},
   "source": [
    "Tokenization & padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9a3ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pad shape: (21976, 40)\n",
      "X_test_pad shape : (5494, 40)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Tokenizer and padded sequences\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)   # fit only on training data\n",
    "\n",
    "# Convert text to sequences of word IDs\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq  = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad / truncate to fixed length\n",
    "X_train_pad = pad_sequences(\n",
    "    X_train_seq,\n",
    "    maxlen=MAX_SEQUENCE_LENGTH,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n",
    "X_test_pad = pad_sequences(\n",
    "    X_test_seq,\n",
    "    maxlen=MAX_SEQUENCE_LENGTH,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n",
    "\n",
    "print(\"X_train_pad shape:\", X_train_pad.shape)\n",
    "print(\"X_test_pad shape :\", X_test_pad.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe460ed9",
   "metadata": {},
   "source": [
    "## 5. Build the BiLSTM model\n",
    "\n",
    "We now define a slightly richer model than the earlier baseline:\n",
    "\n",
    "- `Embedding`: maps word IDs to embedding vectors  \n",
    "- `SpatialDropout1D(0.1)`: regularization  \n",
    "- `Bidirectional(LSTM(128))`: reads the tweet left→right and right→left  \n",
    "- `Dense(64, relu) + Dropout(0.3)`: non-linear layer with moderate dropout  \n",
    "- `Dense(3, softmax)`: outputs probabilities for 3 sentiment classes\n",
    "\n",
    "We use:\n",
    "\n",
    "- `sparse_categorical_crossentropy` (since labels are integer IDs)  \n",
    "- `adam` optimizer  \n",
    "- `accuracy` as the main metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee44fa3",
   "metadata": {},
   "source": [
    "Build & compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf32877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subuntu/anaconda3/envs/tf2/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764163846.407075   77757 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764163846.599892   77757 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764163846.599996   77757 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764163846.603830   77757 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764163846.604336   77757 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764163846.604445   77757 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764163847.292767   77757 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1764163847.293155   77757 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-26 13:30:47.293184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1764163847.293337   77757 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-26 13:30:47.293573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1765 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2050, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Build BiLSTM model\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(\n",
    "        input_dim=MAX_NUM_WORDS,\n",
    "        output_dim=EMBEDDING_DIM,\n",
    "        input_length=MAX_SEQUENCE_LENGTH\n",
    "    ),\n",
    "    layers.SpatialDropout1D(0.1),\n",
    "    Bidirectional(LSTM(128)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3091e35a",
   "metadata": {},
   "source": [
    "## 6. Train the model with EarlyStopping and class weights\n",
    "\n",
    "In the earlier version, the model **ignored the \"negative\" class**,  \n",
    "predicting mostly \"neutral\" and \"positive\".\n",
    "\n",
    "To address this, we:\n",
    "\n",
    "1. Compute **class weights** using `compute_class_weight` (balanced)  \n",
    "2. Pass them to `model.fit(class_weight=...)` so errors on minority/ignored classes  \n",
    "   are penalized more strongly  \n",
    "3. Use `EarlyStopping` on validation loss with `restore_best_weights=True`\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- Watch training `loss/accuracy` vs `val_loss/val_accuracy`  \n",
    "- Training may stop before `EPOCHS` when validation loss stops improving  \n",
    "- After this, we expect non-zero recall for the “negative” class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6aab1a",
   "metadata": {},
   "source": [
    "Class weights & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6443e2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1.1773277617057751, 1: 0.8241824182418241, 2: 1.066899698999903}\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 13:31:03.755533: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 22ms/step - accuracy: 0.5113 - loss: 0.9375 - val_accuracy: 0.7080 - val_loss: 0.6857\n",
      "Epoch 2/15\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.7726 - loss: 0.5480 - val_accuracy: 0.6986 - val_loss: 0.7345\n",
      "Epoch 3/15\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - accuracy: 0.8448 - loss: 0.3895 - val_accuracy: 0.7037 - val_loss: 0.7735\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Compute class weights and train model\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Ensure numeric arrays\n",
    "X_train_pad = np.asarray(X_train_pad, dtype=\"int32\")\n",
    "X_test_pad  = np.asarray(X_test_pad, dtype=\"int32\")\n",
    "y_train     = np.asarray(y_train, dtype=\"int32\")\n",
    "y_test      = np.asarray(y_test, dtype=\"int32\")\n",
    "\n",
    "# Compute class weights to handle any imbalance / ignored classes\n",
    "classes = np.array([0, 1, 2])  # negative, neutral, positive\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = {int(c): float(w) for c, w in zip(classes, class_weights_array)}\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# EarlyStopping callback\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train_pad,\n",
    "    y_train,\n",
    "    validation_data=(X_test_pad, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    "    class_weight=class_weight_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b68137",
   "metadata": {},
   "source": [
    "## 7. Evaluate the model on the test set\n",
    "\n",
    "We now:\n",
    "\n",
    "1. Get prediction probabilities on `X_test_pad`  \n",
    "2. Convert them to predicted class IDs (`argmax`)  \n",
    "3. Print a `classification_report`  \n",
    "4. Print the confusion matrix\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "- **Accuracy** should be noticeably higher than the majority baseline (~40%)  \n",
    "- **\"Negative\" class** should now have non-zero recall and F1-score  \n",
    "- The confusion matrix shows which pairs of classes are still confused."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d915ec",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b48cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.71      0.70      1556\n",
      "     neutral       0.67      0.67      0.67      2222\n",
      "    positive       0.77      0.76      0.77      1716\n",
      "\n",
      "    accuracy                           0.71      5494\n",
      "   macro avg       0.71      0.71      0.71      5494\n",
      "weighted avg       0.71      0.71      0.71      5494\n",
      "\n",
      "Confusion matrix (rows = true, cols = pred):\n",
      "[[1098  382   76]\n",
      " [ 428 1480  314]\n",
      " [  73  331 1312]]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Evaluate on test set\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "target_names = [ID_TO_LABEL[i] for i in range(NUM_CLASSES)]\n",
    "\n",
    "print(\"Classification report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "\n",
    "print(\"Confusion matrix (rows = true, cols = pred):\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd50d3e",
   "metadata": {},
   "source": [
    "## 8. Save model and tokenizer for deployment\n",
    "\n",
    "Finally we:\n",
    "\n",
    "- Save the trained Keras model to `sentiment_model.h5`  \n",
    "- Save the fitted tokenizer to `tokenizer.joblib`\n",
    "\n",
    "Your `app.py` (Streamlit app) will:\n",
    "\n",
    "- Use the **same `clean_text()`** function  \n",
    "- Load `tokenizer.joblib` to tokenize and pad new text  \n",
    "- Load `sentiment_model.h5` to predict probabilities and sentiment labels.\n",
    "\n",
    "This ensures training and inference pipelines stay consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45da969",
   "metadata": {},
   "source": [
    "Save model & tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59efb080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: sentiment_model.h5\n",
      "Saved tokenizer to: tokenizer.joblib\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Save model & tokenizer\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "model.save(MODEL_PATH)\n",
    "dump(tokenizer, TOKENIZER_PATH)\n",
    "\n",
    "print(\"Saved model to:\", MODEL_PATH)\n",
    "print(\"Saved tokenizer to:\", TOKENIZER_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
